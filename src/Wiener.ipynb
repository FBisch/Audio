{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STFT based Wiener filter with forgetting factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "import paths\n",
    "import processing\n",
    "import algorithms\n",
    "\n",
    "import librosa\n",
    "import librosa.core as lc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as sc\n",
    "from scipy.io.wavfile import write\n",
    "import IPython\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: Delayed inputs, speech on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ladida'\n",
    "speech_filename = 'alexa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_0, signal_1, fs = helper.load_separate_channels(filename)\n",
    "IPython.display.Audio(data = signal_0, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speech_signal, _, fs = helper.load_separate_channels(speech_filename)\n",
    "IPython.display.Audio(data = speech_signal, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the signal into two different signals being the two channels.\n",
    "\n",
    "Then we apply a **delay** similar to the one we would roughly have if the two microphones were separated by a certain distance (`6cm` here) by taking into account the sampling frequency (`32000 Hz` here).\n",
    "\n",
    "On top of that, we add a **speech signal** at the same position for both inputs.\n",
    "\n",
    "The current scenario represents a simple case in which the two inputs are only delayed one from another, the speech signal has no delay (we suppose that the speaker is in front of both microphones), and the same channel is applied to both (which is obviously not a realistic case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_0, signal_1 = processing.add_delay(0.06, fs, signal_0)\n",
    "signal_0, signal_1 = processing.add_speech('alexa', signal_0, signal_1, amp=1, position='mid')\n",
    "helper.plot_signals(signal_0, signal_1, 'The two input signals after preparing the setup', 'signal_0', 'signal_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = signal_0, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute the **STFT** for the two signals, with a pre-chosen `window_size` and `hop_percentage` which is the percentage of `window_size` we want to jump over for each consecutive frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Time Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_0, Zxx_1, n_freqs, n_frames, hop_length = helper.dual_stft(signal_0, \n",
    "                                                               signal_1, \n",
    "                                                               window_size=4096, \n",
    "                                                               hop_percentage=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the **STFT based Wiener filter with forgetting factor** algorithm with the parameters we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_1_estimate = algorithms.stft_wiener_filter(Zxx_0, Zxx_1, alpha=0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = Zxx_1 - Zxx_1_estimate\n",
    "epsilon_time = lc.istft(epsilon, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_signals(signal_0, epsilon_time, 'The input and output signals', 'input', 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the spectrograms of the input signal and the output signal. You should be able to see the drop of magnitude after d frames in the second plot, which is the number of frames required to analyse the noise and then filter the signal with a delay of the deferred coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.spectrogram(Zxx_0, epsilon, 1/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = epsilon_time, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: Delayed inputs, speech on top, filtering with 2 Room Impulse Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_0, signal_1, fs = helper.load_separate_channels(filename)\n",
    "IPython.display.Audio(data = signal_0, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speech_signal, _, fs = helper.load_separate_channels(speech_filename)\n",
    "IPython.display.Audio(data = speech_signal, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a **delay** similar to the one we would roughly have if the two microphones were separated by a certain distance (`6cm` here) by taking into account the sampling frequency (`32000 Hz` here).\n",
    "\n",
    "On top of that, we add a **speech signal** at the same position for both inputs.\n",
    "\n",
    "Finally, we filter the first signal (the one wich has \"no delay\" introduced) with a `close_mic_rir` **Room Impulse Response** (RIR), simulating a close microphone, and the second signal with a `far_mic_rir` **Room Impulse Response** (RIR), simulating a far microphone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_0, signal_1 = processing.add_delay(0.06, fs, signal_0)\n",
    "signal_0, signal_1 = processing.add_speech('alexa', signal_0, signal_1, amp=1, position='mid')\n",
    "signal_0 = processing.rir_filter('close_mic_rir', 44100, signal_0, resampling_f=fs)\n",
    "signal_1 = processing.rir_filter('far_mic_rir', 44100, signal_1, resampling_f=fs)\n",
    "helper.plot_signals(signal_0, signal_1, 'The two input signals after preparing the setup', 'signal_0', 'signal_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = signal_1, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Time Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_0, Zxx_1, n_freqs, n_frames, hop_length = helper.dual_stft(signal_0, \n",
    "                                                               signal_1, \n",
    "                                                               window_size=8192, \n",
    "                                                               hop_percentage=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_1_estimate = algorithms.stft_wiener_filter(Zxx_0, Zxx_1, alpha=0.00008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = Zxx_1 - Zxx_1_estimate\n",
    "epsilon_time = lc.istft(epsilon, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_signals(signal_0, epsilon_time, 'The input and output signals', 'input', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.spectrogram(Zxx_0, epsilon, 1/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = epsilon_time, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3: Original signals from the recording, and speech on top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_0, signal_1, fs = helper.load_separate_channels(filename)\n",
    "IPython.display.Audio(data = signal_0, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speech_signal, _, fs = helper.load_separate_channels(speech_filename)\n",
    "IPython.display.Audio(data = speech_signal, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we do not touch the original noise, and add the speech on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_0, signal_1 = processing.add_speech('alexa', signal_0, signal_1, amp=1, position='mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_signals(signal_0, signal_1, 'The two input signals', 'signal_0', 'signal_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = signal_1, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Time Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_0, Zxx_1, n_freqs, n_frames, hop_length = helper.dual_stft(signal_0, \n",
    "                                                               signal_1, \n",
    "                                                               window_size=8192, \n",
    "                                                               hop_percentage=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_1_estimate = algorithms.stft_wiener_filter(Zxx_0, Zxx_1, alpha=0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = Zxx_1 - Zxx_1_estimate\n",
    "epsilon_time = lc.istft(epsilon, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_signals(signal_0, epsilon_time, 'The input and output signals', 'input', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.spectrogram(Zxx_0, epsilon, 1/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = epsilon_time, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 4: Original signals from the recording containing the speech signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ladida_real'\n",
    "signal_0, signal_1, fs = helper.load_separate_channels(filename)\n",
    "IPython.display.Audio(data = signal_0, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the signals already contain the speech signal. Everything was recorded together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_signals(signal_0, signal_1, 'The two input signals', 'signal_0', 'signal_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = signal_1, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Time Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_0, Zxx_1, n_freqs, n_frames, hop_length = helper.dual_stft(signal_0, \n",
    "                                                               signal_1, \n",
    "                                                               window_size=32000, \n",
    "                                                               hop_percentage=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_1_estimate = algorithms.stft_wiener_filter(Zxx_0, Zxx_1, alpha=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = Zxx_1 - Zxx_1_estimate\n",
    "epsilon_time = lc.istft(epsilon, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_signals(signal_0, epsilon_time, 'The input and output signals', 'input', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.spectrogram(Zxx_0, epsilon, 1/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = epsilon_time, rate = fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
